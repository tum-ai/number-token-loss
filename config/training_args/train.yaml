output_dir: "outputs/${dataset_args.dataset_name}/${training_args.trial}/${model_args.name}_${training_args.special_name}/"
learning_rate: 1e-4
lr_scheduler_type: reduce_lr_on_plateau
lr_scheduler_kwargs:
  factor: 0.5
  patience: 5
weight_decay: 0.01
num_train_epochs: 2000
save_total_limit: 2
save_steps: 25000
eval_steps: 25000
per_device_train_batch_size: 32
per_device_eval_batch_size: 64
logging_steps: 2000
report_to: wandb
eval_on_start: true