{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:12:13.336967Z",
     "start_time": "2024-07-26T15:12:12.813914Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "### Huggingface dataset and tokenizer imports\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import XLNetTokenizer\n",
    "\n",
    "from src.tokenizer.xval_tokenizer import XvalTokenizer\n",
    "from src.transformer_backbone.xlnet import XLNetBackbone\n",
    "from src.encoding_decoding.xval_encoding_decoding import XValModel, define_masked_num_collator as xval_define_masked_num_collator\n",
    "\n",
    "from src.tokenizer.rt_tokenizer import RtTokenizer\n",
    "from src.encoding_decoding.rt_encoding_decoding import RegressionTransformer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c392a36ea5f62d6a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "972c6bb08541c62",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T15:12:15.600051Z",
     "start_time": "2024-07-26T15:12:15.301852Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to read the text file and yield examples\n",
    "def read_txt(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for i in range(0, len(lines), 2):\n",
    "        question = lines[i].strip()\n",
    "        answer = lines[i+1].strip()\n",
    "        yield {'question': question, 'answer': answer}\n",
    "\n",
    "# Define the dataset loading function\n",
    "def load_txt_dataset(file_path):\n",
    "    return Dataset.from_generator(read_txt, gen_kwargs={'file_path': file_path})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a43a0143e570d4f8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T15:12:18.034206Z",
     "start_time": "2024-07-26T15:12:17.371105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['question', 'answer'],\n    num_rows: 117\n})"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './data/mathematics_dataset-v1.0/mathematics_dataset-v1.0/train-easy/algebra__linear_1d_small.txt'\n",
    "\n",
    "ds = load_txt_dataset(data_path)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eeb30d4c54bafe5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T15:12:19.212191Z",
     "start_time": "2024-07-26T15:12:18.803672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Solve 0 = 4*b + b + 15 for b.'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"question\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86262376ecabca53",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T15:12:20.352815Z",
     "start_time": "2024-07-26T15:12:19.749813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'-3'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"answer\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bc3538d10a02c9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load pretrained Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aef0cc1850ecd0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:45:01.201049Z",
     "start_time": "2024-07-07T18:44:57.916088Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonas\\anaconda3\\envs\\xval\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"xlnet-base-cased\"\n",
    "pretrained_tokenizer = XLNetTokenizer.from_pretrained(model_name)\n",
    "transformer_backbone = XLNetBackbone(model_name).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bf788e466c764",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Xval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ff4eaf104d230a9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T15:15:46.088875Z",
     "start_time": "2024-07-26T15:15:45.325872Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'XvalTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer =XvalTokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75805a22e73ef981",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T15:15:47.260269Z",
     "start_time": "2024-07-26T15:15:46.778152Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_x = tokenizer(ds[0][\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e65bb8917b18364",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T15:16:13.402523Z",
     "start_time": "2024-07-26T15:16:12.820533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve 0 = 4*b + b + 15 for b.\n",
      "['Sol', 've', '[NUM]', '=', '[NUM]', '*', 'b', '+', '', 'b', '+', '[NUM]', 'for', '', 'b', '.', '</s>']\n",
      "[1.0, 1.0, 0.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 15.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(ds[0][\"question\"])\n",
    "print([tokenizer.decode(x) for x in tokenized_x[\"input_ids\"]])\n",
    "print([x for x in tokenized_x[\"number_embeddings\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb82958cbc325764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:45:06.227585Z",
     "start_time": "2024-07-07T18:45:05.902582Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting tokenization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8fbc6c22a84402919e9ce46e5635af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nStarting tokenization...\")\n",
    "tokenize_lambda = lambda x: {\"question\": tokenizer(x[\"question\"]), \"answer\": tokenizer(x[\"answer\"])}\n",
    "tokenized_ds = ds.map(\n",
    "    tokenize_lambda,\n",
    "    batched=False,\n",
    "    # num_proc=30,\n",
    "    load_from_cache_file=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f20637e1e61277ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:45:18.817677Z",
     "start_time": "2024-07-07T18:45:18.116404Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = XValModel(transformer_backbone=transformer_backbone, vocab_size=len(tokenizer.tokenizer), dim_feedforward=1536, context_length=955).cuda()\n",
    "\n",
    "pad_token_id = tokenizer.tokenizer.pad_token_id\n",
    "mask_token_id = tokenizer.tokenizer.mask_token_id\n",
    "mlm_probability = 0.3\n",
    "epochs = 10\n",
    "lr = 1e-4\n",
    "weight_decay = 0.01\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "collator = xval_define_masked_num_collator(pad_token_id, mask_token_id, mlm_probability)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_ds[\"question\"],\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce76f62915627ec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:46:38.610557Z",
     "start_time": "2024-07-07T18:45:19.860560Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:06<00:57,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0: loss_mlm = 11.248; loss_num = 51407.855; loss_total = 51419.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:13<00:55,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: loss_mlm = 11.126; loss_num = 81999.289; loss_total = 82010.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:22<00:53,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: loss_mlm = 10.889; loss_num = 82899.489; loss_total = 82910.380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:30<00:46,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: loss_mlm = 10.618; loss_num = 82658.826; loss_total = 82669.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:39<00:42,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: loss_mlm = 10.362; loss_num = 124809.849; loss_total = 124820.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:48<00:34,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: loss_mlm = 10.089; loss_num = 159113.855; loss_total = 159123.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:56<00:24,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: loss_mlm = 9.815; loss_num = 156969.954; loss_total = 156979.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:03<00:16,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: loss_mlm = 9.553; loss_num = 158357.218; loss_total = 158366.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:11<00:07,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: loss_mlm = 9.294; loss_num = 152996.410; loss_total = 153005.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:18<00:00,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: loss_mlm = 9.044; loss_num = 149240.996; loss_total = 149250.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_hist = []\n",
    "loss_mlm_hist = []\n",
    "loss_num_hist = []\n",
    "\n",
    "max_n_batches = 100\n",
    "\n",
    "try:\n",
    "    for e in tqdm(range(epochs)):\n",
    "        n_batches = 0\n",
    "        for batch in train_loader:\n",
    "            if n_batches > max_n_batches:\n",
    "                break\n",
    "            logit_preds, num_preds = model(\n",
    "                batch[\"x\"].cuda(),\n",
    "                batch[\"x_num\"].cuda(),\n",
    "                batch[\"attention_mask\"].cuda(),\n",
    "                batch[\"token_type_ids\"].cuda(),\n",
    "            )\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                loss_mlm = F.cross_entropy(\n",
    "                    logit_preds.view(-1, logit_preds.size(-1)),\n",
    "                    batch[\"y\"].cuda().view(-1),\n",
    "                    ignore_index=-100,\n",
    "                    reduction=\"mean\",\n",
    "                )\n",
    "                num_mask = batch['y'] == tokenizer.tokenizer.convert_tokens_to_ids(\"[NUM]\")\n",
    "                loss_num = F.mse_loss(\n",
    "                    num_preds[num_mask],\n",
    "                    batch[\"y_num\"][num_mask].view(-1, 1).cuda(),\n",
    "                    reduction=\"mean\",\n",
    "                )\n",
    "            loss = loss_mlm + loss_num\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_hist.append(loss.item())\n",
    "            loss_mlm_hist.append(loss_mlm.item())\n",
    "            loss_num_hist.append(loss_num.item())\n",
    "            n_batches += 1\n",
    "\n",
    "            try:\n",
    "                loss_avg = 0.99 * loss_avg + 0.01 * loss.item()\n",
    "                loss_mlm_avg = 0.99 * loss_mlm_avg + 0.01 * loss_mlm.item()\n",
    "                loss_num_avg = 0.99 * loss_num_avg + 0.01 * loss_num.item()\n",
    "            except:\n",
    "                loss_avg = loss.item()\n",
    "                loss_mlm_avg = loss_mlm.item()\n",
    "                loss_num_avg = loss_num.item()\n",
    "\n",
    "        checkpoint = {\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"loss\": loss_avg,\n",
    "            \"loss_hist\": loss_hist,\n",
    "            \"loss_mlm_hist\": loss_mlm_hist,\n",
    "            \"loss_num_hist\": loss_num_hist,\n",
    "        }\n",
    "        torch.save(checkpoint, \"./ckpt.pt\")\n",
    "        print(f\"Epoch #{e}: loss_mlm = {loss_mlm_avg:.3f}; loss_num = {loss_num_avg:.3f}; loss_total = {loss_avg:.3f}\")\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b217ca79fdbf3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Regression Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "672989b5106f7d13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:19.751330Z",
     "start_time": "2024-07-07T18:50:19.518014Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_num_tokens(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return [line.strip() for line in lines]\n",
    "\n",
    "num_tokens = read_num_tokens(\"regression_transformer_number_tokens.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c99ec783ffb8b291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:20.346729Z",
     "start_time": "2024-07-07T18:50:20.194606Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_0_0_', '_1_0_', '_2_0_', '_3_0_', '_4_0_']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a628e81c204ef57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:21.026171Z",
     "start_time": "2024-07-07T18:50:20.882772Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = RtTokenizer(pretrained_tokenizer, num_tokens, embedding_dim=transformer_backbone.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78c7b66f6dc69c4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:21.791106Z",
     "start_time": "2024-07-07T18:50:21.631155Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve 0 = 4*b + b + 15 for b.\n"
     ]
    }
   ],
   "source": [
    "print(ds[0][\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3ce7bbb3a3f2821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:22.818744Z",
     "start_time": "2024-07-07T18:50:22.614624Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve 0 = 4*b + b + 15 for b.\n",
      "['Sol', 've', '_0_0_', '=', '_4_0_', '*', 'b', '+', '', 'b', '+', '_1_1_', '_5_0_', 'for', '', 'b', '.', '<sep>', '<cls>']\n",
      "[0.0, 0.0, 0.0, 0.0, 2.7699864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.9249663, 3.4624832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "tokenized_x = tokenizer(ds[0][\"question\"])\n",
    "print(ds[0][\"question\"])\n",
    "print([tokenizer.tokenizer.decode(x) for x in tokenized_x[\"input_ids\"]])\n",
    "print([x.sum() for x in tokenized_x[\"number_embeddings\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "423fea9a7bd46a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:26.555983Z",
     "start_time": "2024-07-07T18:50:25.826365Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting tokenization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406476198d0b48c8b30eb2ae0f58c3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nStarting tokenization...\")\n",
    "tokenize_lambda = lambda x: {\"question\": tokenizer(x[\"question\"]), \"answer\": tokenizer(x[\"answer\"])}\n",
    "tokenized_ds = ds.map(\n",
    "    tokenize_lambda,\n",
    "    batched=False,\n",
    "    # num_proc=30,\n",
    "    load_from_cache_file=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d895cb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faddff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Initialize our Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset if training_args.do_train else None,\n",
    "        eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics if training_args.do_eval and not is_torch_xla_available() else None,\n",
    "        preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
    "        if training_args.do_eval and not is_torch_xla_available()\n",
    "        else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a879c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2856ff1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1447c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e919f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac466b2397ff20ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:28.589883Z",
     "start_time": "2024-07-07T18:50:27.075860Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RegressionTransformer(transformer_backbone=transformer_backbone, vocab_size=len(tokenizer.tokenizer), dim_feedforward=1536,\n",
    "                  context_length=955).cuda()\n",
    "\n",
    "pad_token_id = tokenizer.tokenizer.pad_token_id\n",
    "mask_token_id = tokenizer.tokenizer.mask_token_id\n",
    "mlm_probability = 0.3\n",
    "epochs = 10\n",
    "lr = 1e-4\n",
    "weight_decay = 0.01\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "collator = rt_define_masked_num_collator(pad_token_id, mask_token_id, mlm_probability)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_ds[\"question\"],\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd75124d4f0b53ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:53:11.737055Z",
     "start_time": "2024-07-07T18:50:29.190812Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:19<02:59, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0: loss = 143369.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:36<02:25, 18.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: loss = 137720.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:56<02:10, 18.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: loss = 132293.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:13<01:47, 17.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: loss = 127081.060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:27<01:23, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: loss = 122073.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:49<01:13, 18.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: loss = 117263.670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:02<00:49, 16.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: loss = 112643.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:16<00:31, 15.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: loss = 108204.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [02:29<00:14, 14.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: loss = 103941.141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:42<00:00, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: loss = 99845.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_hist = []\n",
    "\n",
    "max_n_batches = 100\n",
    "\n",
    "try:\n",
    "    for e in tqdm(range(epochs)):\n",
    "        n_batches = 0\n",
    "        for batch in train_loader:\n",
    "            if n_batches > max_n_batches:\n",
    "                break\n",
    "            logit_preds = model(\n",
    "                batch[\"x\"].cuda(),\n",
    "                batch[\"number_embeddings\"].cuda(),\n",
    "                batch[\"attention_mask\"].cuda(),\n",
    "                batch[\"token_type_ids\"].cuda(),\n",
    "            )\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                loss = F.cross_entropy(\n",
    "                    logit_preds.view(-1, logit_preds.size(-1)),\n",
    "                    batch[\"y\"].cuda().view(-1),\n",
    "                    ignore_index=-100,\n",
    "                    reduction=\"mean\",\n",
    "                )\n",
    "               \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_hist.append(loss.item())\n",
    "            n_batches += 1\n",
    "\n",
    "            try:\n",
    "                loss_avg = 0.99 * loss_avg + 0.01 * loss.item()\n",
    "            except:\n",
    "                loss_avg = loss.item()\n",
    "\n",
    "        checkpoint = {\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"loss\": loss_avg,\n",
    "            \"loss_hist\": loss_hist,\n",
    "        }\n",
    "        torch.save(checkpoint, \"./ckpt.pt\")\n",
    "        print(f\"Epoch #{e}: loss = {loss_avg:.3f}\")\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b064a020a15d1f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
